# AWS for Data Engineering - Advanced

## I. Expert-level AWS for Data Engineering

1. **Serverless Architectures:** 
   - Advanced concepts of serverless architectures using AWS Lambda and other serverless services.

2. **Big Data Analytics:** 
   - Advanced analytics using services like Amazon EMR, Amazon Redshift, and Amazon Athena for big data.

3. **Data Lakes:** 
   - Design and implementation of data lakes on AWS using services like Amazon S3 and AWS Glue.

4. **Advanced Security:** 
   - Advanced security practices and compliance in AWS data engineering.

5. **High Availability and Disaster Recovery:** 
   - Strategies for high availability and disaster recovery in AWS data engineering solutions.

6. **Performance Optimization:** 
   - Techniques for optimizing performance of AWS data engineering solutions.

### Summary

This checklist covers expert-level AWS services and concepts for data engineering, including serverless architectures, big data analytics, data lakes, and advanced security and compliance practices.

### Projects
-[Cloud_Data_Warehouses](https://github.com/Lal4Tech/Data-Engineering-With-AWS/tree/main/2_Cloud_Data_Warehouses/project) : A music streaming startup, Sparkify, has grown their user base and song database and want to move their processes and data onto the cloud. Their data resides in S3, in a directory of JSON logs on user activity on the app, as well as a directory with JSON metadata on the songs in their app)

-[ETL Pipeline for Pre-Processing the Files](https://github.com/Lal4Tech/Data-Engineering-With-AWS/blob/main/1_Data_Modelling/project/data_modelling_project.ipynb)

-[STEDI Human Balance Analytics](https://github.com/Lal4Tech/Data-Engineering-With-AWS/blob/main/3_Spark_and_Data_Lakes/project/README.md)

-[Project: Data Pipelines with Airflow](https://github.com/Lal4Tech/Data-Engineering-With-AWS/blob/main/4_Automate_Data_Pipelines/project/README.md)
